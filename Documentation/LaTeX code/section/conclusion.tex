\section{Conclusion and future work}

\subsection{Conclusion}
A lot of work and hours were spent creating and optimizing all the processes. These processes include gathering data, extracting details, and display them in a user-friendly way.
Right now, a user can get data from the API automatically and concatenate it thanks to a script.
After that, all the user has to do is to load the data into a Jupyter Notebook, which will automatically do the sentiment analysis.
The \gls{plot} functions are ready, so the user will be able to \gls{plot} all the data he imported.

This work has opened my eyes to the world of data. I had never considered sentiment analysis and having it in newspapers made me realize the importance of data in everyday life.

This work could very well be part of studying a psychological thesis on the masses, to see how the polarity of the news can affect the masses.
Specifically today, where the news is mostly negative, see the influence it has on the individual person.

Personally, I find it very important how the news is given to us, whether it is true or not, and whether it is possible to improve this situation.

Perhaps through this work, people can realize the negativity of certain news outlets and become aware that the world is not as bad as they portray it.

\subsection{Future Work}
There is a lot of work that can be tackled in the future. Some ideas are listed in this section, but there is by far more potential.

\subsubsection{Back-End}
\subsubsection*{Improve data quality}
For the project I used two APIs to get data from the internet, for the future it would be better to do a manual scraping of the data.
By doing a manual scraping it is possible to choose many more newspapers, and especially take the ones that are more specific to the area.
Besides that, manual scraping, it allows to have much more data from a single newspaper.

\subsubsection*{Improve accuracy model}
The model has an \gls{accuracy} of 93\%, this is because a specific dataset on movie reviews was used.
One way to increase the \gls{accuracy} is to have different datasets, the best option would be to have a dataset on newspaper articles, so that the model already trains on different categories and specific topics, also learning the words better.

\subsubsection*{Improve technology}
Technology is always moving, for this reason it is better to keep updated the model or to create it with the technologies present at the moment of speaking.
In fact, just today has been released the new version of \gls{Tensorflow} with many improvements.


\subsubsection{Front-End}
\subsubsection*{User interface}
The creation of an application with a user interface, would allow the user to be able to better use this data as a tool.

In addition, the user interface or website should better explain the statistics obtained, making it easier for the user.
